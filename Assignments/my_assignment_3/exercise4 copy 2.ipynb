{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/08 19:42:38 WARN Utils: Your hostname, Christofoross-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.5.40.38 instead (on interface en0)\n",
      "25/04/08 19:42:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/08 19:42:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "import os\n",
    "os.chdir('/Users/chkapsalis/Documents/GitHub/Big_Data_Architectures/Assignments/my_assignment_3')\n",
    "\n",
    "# For some reason i need to run this every time in order to get it work\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/opt/homebrew/opt/openjdk@11/libexec/openjdk.jdk/Contents/Home\" \n",
    "\n",
    "spark = SparkContext(\"local[1]\", \"app\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile= spark.textFile('file:///' + os.getcwd() + '/Global_Cybersecurity_Threats_2015-2024.csv')\n",
    "\n",
    "import datetime \n",
    "\n",
    "def parse(row):\n",
    "    \"\"\" This function allows for the more straightforward ingestion of the file's contents per line. \n",
    "    It also facilitates making sure we ignore any invalid lines\"\"\"\n",
    "    try:\n",
    "        country = row[0]\n",
    "        year = int(row[1])\n",
    "        attack_type = row[2]\n",
    "        target_industry = row[3]\n",
    "        fin_loss = float(row[4])\n",
    "        no_affected_users = int(row[5])\n",
    "        vulnerability_type = row[7]\n",
    "        resolution_time = int(row[9])\n",
    "        return (country, year, attack_type, target_industry, fin_loss, no_affected_users,resolution_time)\n",
    "    except:\n",
    "        return  # Ignore invalid lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will ingest all data of interest pertaining to flights; date,airline code,arr_delay,dept_delay\n",
    "attacks = datafile.map(lambda full_line: full_line.split(',')) \\\n",
    "                .map(parse) \\\n",
    "                .filter(lambda x: x is not None).cache()  # this rdd will be used multiple times throughout the\n",
    "                # exercise, so I cache its evaluation into the primary memory, to prevent spark from \n",
    "                # repeating the transformations that lead to it multiple times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('China', 2019, 'Phishing', 'Education', 80.53, 773169, 63)\n",
      "('China', 2019, 'Ransomware', 'Retail', 62.19, 295961, 71)\n",
      "('India', 2017, 'Man-in-the-Middle', 'IT', 38.65, 605895, 20)\n",
      "('UK', 2024, 'Ransomware', 'Telecommunications', 41.44, 659320, 7)\n",
      "('Germany', 2018, 'Man-in-the-Middle', 'IT', 74.41, 810682, 68)\n"
     ]
    }
   ],
   "source": [
    "for x in attacks.take(5):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('China', 13714.469999999988), ('India', 14566.119999999997), ('UK', 16502.98999999999), ('Germany', 15793.240000000002), ('France', 14972.280000000019), ('Australia', 15402.999999999996), ('Russia', 14734.73), ('Brazil', 15782.62000000001), ('Japan', 15197.34000000001), ('USA', 14812.12)]\n"
     ]
    }
   ],
   "source": [
    "### Question 1: Calculate total financial loss per country\n",
    "# I create (country, fin_loss_value) pairs\n",
    "total_loss_per_country = attacks.map(lambda x: (x[0], x[4])) \\\n",
    "                .reduceByKey(lambda x, y: x+y) \\\n",
    "                .collect()\n",
    "\n",
    "print(total_loss_per_country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (2228443910.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    .map(lambda x: (1, x[5])) \\\u001b[0m\n\u001b[0m                                \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "### Question 2: Overall average number of affected users across attacks\n",
    "count_attacks, sum_users_affected = attacks.map(lambda x: ()) \\\n",
    "                    .map(lambda x: (1, x[5])) \\\n",
    "                .reduce(lambda x, y: (x[0] + y[0], x[1] + y[1])) \\\n",
    "                .map(lambda x: x[1] / x[0]) \\\n",
    "                .collect()\n",
    "print(count_attacks, sum_users_affected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+\n",
      "| Name|      date|   volume|\n",
      "+-----+----------+---------+\n",
      "|   VZ|2014-02-24|618237630|\n",
      "|   GE|2015-11-17|431332632|\n",
      "|  BAC|2016-02-11|375088650|\n",
      "|   FB|2013-07-25|365380568|\n",
      "|  PFE|2016-04-05|284468054|\n",
      "|  MRO|2016-03-01|273996613|\n",
      "|  AMD|2017-05-02|268336455|\n",
      "| AAPL|2014-01-28|266833581|\n",
      "|  KMI|2014-11-26|251563883|\n",
      "| MSFT|2013-07-19|248354245|\n",
      "| CSCO|2013-11-14|243255407|\n",
      "|    F|2013-12-18|220362796|\n",
      "| AMAT|2015-04-27|219415189|\n",
      "|  DAL|2013-09-10|206363059|\n",
      "|  CHK|2016-03-04|188966428|\n",
      "| NFLX|2013-10-22|181099968|\n",
      "|CMCSA|2014-02-13|166551204|\n",
      "| ORCL|2013-07-12|157674694|\n",
      "|   MU|2013-10-11|153906087|\n",
      "|  FCX|2016-01-12|141597285|\n",
      "+-----+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OPTION B - SPARKSQL\n",
    "\n",
    "stocks.createOrReplaceTempView(\"stocks\")\n",
    "query = spark.sql(\"\"\"\n",
    "    SELECT s.Name, s.date, s.volume\n",
    "    FROM stocks s\n",
    "    INNER JOIN (\n",
    "        SELECT Name, MAX(volume) AS max_volume\n",
    "        FROM stocks\n",
    "        GROUP BY Name\n",
    "    ) m\n",
    "    ON s.Name = m.Name AND s.volume = m.max_volume\n",
    "    ORDER BY s.volume DESC\n",
    "\"\"\")\n",
    "\n",
    "query.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "avg_volume_per_month = stocks \\\n",
    "    .select(\n",
    "        date_format(col(\"date\"), \"MMM yyyy\").alias(\"date\"),  # I need to express dates as month values to group by those\n",
    "        col(\"volume\")\n",
    "    ) \\\n",
    "    .groupBy(col(\"date\")) \\\n",
    "    .agg(avg(\"volume\").alias(\"avg_volume\")) \\\n",
    "    .orderBy(col(\"date\"), ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|    date|        avg_volume|\n",
      "+--------+------------------+\n",
      "|Apr 2013| 4990292.249235766|\n",
      "|Apr 2014| 4712436.740587831|\n",
      "|Apr 2015|4049128.5425065733|\n",
      "|Apr 2016| 4403273.369344325|\n",
      "|Apr 2017|3879889.4020380294|\n",
      "|Aug 2013|3936255.4692568844|\n",
      "|Aug 2014|  3277133.94670969|\n",
      "|Aug 2015| 4910543.650503291|\n",
      "|Aug 2016|3645052.5863453816|\n",
      "|Aug 2017|3479362.4257066296|\n",
      "|Dec 2013|4092123.8206644976|\n",
      "|Dec 2014|3991512.5363263786|\n",
      "|Dec 2015| 4406736.627640037|\n",
      "|Dec 2016|4130377.3358465354|\n",
      "|Dec 2017|3919747.9897999605|\n",
      "|Feb 2013|  5261788.80732293|\n",
      "|Feb 2014| 4918514.594747739|\n",
      "|Feb 2015| 4254824.743407599|\n",
      "|Feb 2016| 5756484.877016129|\n",
      "|Feb 2017| 4255274.505789474|\n",
      "+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "avg_volume_per_month.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION B - SPARKSQL\n",
    "\n",
    "r2 = spark.sql(\"\"\"\n",
    "\n",
    "    SELECT \n",
    "        date_format(date, \"MMM yyyy\") AS month,\n",
    "        AVG(volume) AS avg_volume\n",
    "    FROM stocks\n",
    "    GROUP BY date_format(date, \"MMM yyyy\")\n",
    "    ORDER BY month ASC\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|   month|        avg_volume|\n",
      "+--------+------------------+\n",
      "|Apr 2013| 4990292.249235766|\n",
      "|Apr 2014| 4712436.740587831|\n",
      "|Apr 2015|4049128.5425065733|\n",
      "|Apr 2016| 4403273.369344325|\n",
      "|Apr 2017|3879889.4020380294|\n",
      "|Aug 2013|3936255.4692568844|\n",
      "|Aug 2014|  3277133.94670969|\n",
      "|Aug 2015| 4910543.650503291|\n",
      "|Aug 2016|3645052.5863453816|\n",
      "|Aug 2017|3479362.4257066296|\n",
      "|Dec 2013|4092123.8206644976|\n",
      "|Dec 2014|3991512.5363263786|\n",
      "|Dec 2015| 4406736.627640037|\n",
      "|Dec 2016|4130377.3358465354|\n",
      "|Dec 2017|3919747.9897999605|\n",
      "|Feb 2013|  5261788.80732293|\n",
      "|Feb 2014| 4918514.594747739|\n",
      "|Feb 2015| 4254824.743407599|\n",
      "|Feb 2016| 5756484.877016129|\n",
      "|Feb 2017| 4255274.505789474|\n",
      "+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "r2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3\n",
    "avg_volume_per_tick = stocks \\\n",
    "    .select(\n",
    "        col(\"Name\"),\n",
    "        col(\"volume\")\n",
    "    ) \\\n",
    "    .groupBy(col(\"Name\")) \\\n",
    "    .agg(avg(\"volume\").alias(\"avg_volume\")) \\\n",
    "    .orderBy(col(\"avg_volume\"), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "| Name|          avg_volume|\n",
      "+-----+--------------------+\n",
      "|  BAC| 9.363379951628277E7|\n",
      "| AAPL| 5.404789973550437E7|\n",
      "|   GE| 4.211568283240667E7|\n",
      "|    F|  3.44623748943606E7|\n",
      "|   FB| 3.435926520969023E7|\n",
      "| MSFT| 3.386946274583002E7|\n",
      "|  AMD| 3.251903779666402E7|\n",
      "|   MU| 3.024841118903892E7|\n",
      "| INTC|2.9326713900714852E7|\n",
      "| CSCO|2.8654349631453533E7|\n",
      "|  PFE|2.8218910923749007E7|\n",
      "|    T|2.5298330478951547E7|\n",
      "|  CHK|2.4957711172359016E7|\n",
      "|CMCSA|2.4329297557585385E7|\n",
      "|  FCX| 2.354921657426529E7|\n",
      "|    C| 2.068675837807784E7|\n",
      "|  WFC|1.8511480962668784E7|\n",
      "|  JPM|1.6589033246227164E7|\n",
      "|   RF|1.6398451548848292E7|\n",
      "| NFLX|1.6208007963463066E7|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_volume_per_tick.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------+\n",
      "| Name|      Date|    Spread|\n",
      "+-----+----------+----------+\n",
      "| AMZN|2018-02-05| 138.26001|\n",
      "| PCLN|2017-11-07|109.900024|\n",
      "|  CMG|2015-11-20|      80.5|\n",
      "|  AZO|2017-12-05| 59.695007|\n",
      "| GOOG|2018-02-06| 58.569946|\n",
      "|GOOGL|2018-02-05|     58.25|\n",
      "| REGN|2015-09-28|    56.905|\n",
      "| PRGO|2015-04-08| 51.097992|\n",
      "|  HUM|2015-05-29| 43.384995|\n",
      "| ULTA|2015-08-24|  43.22001|\n",
      "|  MCK|2015-08-24|   42.1799|\n",
      "|  HCA|2015-08-24|     42.06|\n",
      "| BIIB|2014-03-21| 41.920013|\n",
      "| ALGN|2017-12-04| 35.249985|\n",
      "|  BLK|2018-02-05|  34.53003|\n",
      "|  ADS|2016-01-28| 33.569992|\n",
      "|  MTD|2018-02-05|  33.25952|\n",
      "|   BA|2018-02-05| 32.609985|\n",
      "|  AGN|2015-10-21| 32.499893|\n",
      "|  TDG|2017-01-20|     32.25|\n",
      "+-----+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "\n",
    "# Step 0: Create a new DataFrame with the spread column\n",
    "stocks_with_spread = stocks.withColumn(\"spread\", col(\"high\") - col(\"low\"))\n",
    "\n",
    "# Step 1: Compute max spread per stock\n",
    "max_spread_per_stock = stocks_with_spread.groupBy(\"Name\") \\\n",
    "    .agg(max(\"spread\").alias(\"max_spread\"))\n",
    "\n",
    "# Step 2: Alias both DataFrames before join\n",
    "stocks_alias = stocks_with_spread.alias(\"s\")\n",
    "max_spread_alias = max_spread_per_stock.alias(\"m\")\n",
    "\n",
    "# Step 3: Join and select desired columns\n",
    "max_spread_dates = stocks_alias \\\n",
    "    .join(\n",
    "        max_spread_alias,\n",
    "        (col(\"s.Name\") == col(\"m.Name\")) &\n",
    "        (col(\"s.spread\") == col(\"m.max_spread\")),\n",
    "        how=\"inner\"\n",
    "    ) \\\n",
    "    .select(\n",
    "        col(\"s.Name\").alias(\"Name\"),\n",
    "        col(\"s.date\").alias(\"Date\"),\n",
    "        col(\"s.spread\").alias(\"Spread\")\n",
    "    ) \\\n",
    "    .orderBy(col(\"Spread\").desc())\n",
    "\n",
    "max_spread_dates.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "| Name|   avg_stock_price|\n",
      "+-----+------------------+\n",
      "| PCLN|1346.7126984126985|\n",
      "|  AZO| 768.8588492063492|\n",
      "|GOOGL| 763.2142063492068|\n",
      "| GOOG| 743.4851190476194|\n",
      "| AMZN| 699.5231349206346|\n",
      "|  CMG|428.56464285714287|\n",
      "| REGN|394.49996031746036|\n",
      "|  MTD| 375.5649206349207|\n",
      "|  BLK|350.08837301587295|\n",
      "| EQIX|343.77674603174603|\n",
      "| BIIB| 280.1989682539682|\n",
      "|  SHW| 277.9422222222223|\n",
      "| ORLY|269.24904761904753|\n",
      "|  TDG|251.80250000000007|\n",
      "|  AGN|241.69857142857143|\n",
      "|  AYI|241.64035714285708|\n",
      "|  PSA|238.75015873015872|\n",
      "|  LMT|237.99261904761906|\n",
      "| CHTR|229.49678571428566|\n",
      "| ULTA|224.08111111111108|\n",
      "+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Question 5\n",
    "avg_volume_per_tick = stocks \\\n",
    "    .select(\n",
    "        col(\"Name\"),\n",
    "        col(\"close\")\n",
    "    ) \\\n",
    "    .filter(date_format(col(\"date\"), \"yyyy\") == 2016) \\\n",
    "    .groupBy(col(\"Name\")) \\\n",
    "    .agg(avg(\"close\").alias(\"avg_stock_price\")) \\\n",
    "    .orderBy(col(\"avg_stock_price\"), ascending=False) \n",
    "\n",
    "avg_volume_per_tick.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|Name|\n",
      "+----+\n",
      "|ALXN|\n",
      "| GIS|\n",
      "|   K|\n",
      "| LEN|\n",
      "|SPGI|\n",
      "| AIV|\n",
      "| AVY|\n",
      "|BF.B|\n",
      "| MMM|\n",
      "| PKI|\n",
      "| PPG|\n",
      "|  RF|\n",
      "| AXP|\n",
      "|  CI|\n",
      "| IRM|\n",
      "| WEC|\n",
      "|INFO|\n",
      "| PFG|\n",
      "|  PM|\n",
      "| SNA|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 6\n",
    "\n",
    "all_tickers = stocks \\\n",
    "    .select(col(\"Name\")) \\\n",
    "    .distinct() \n",
    "\n",
    "all_tickers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
