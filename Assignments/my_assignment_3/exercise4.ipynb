{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import col, to_date, date_format, to_timestamp, substring, max, avg\n",
    "os.chdir('/Users/chkapsalis/Documents/GitHub/Big_Data_Architectures/Assignments/my_assignment_3')\n",
    "\n",
    "# For some reason i need to run this every time in order to get it work\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/opt/homebrew/opt/openjdk@11/libexec/openjdk.jdk/Contents/Home\" \n",
    "\n",
    "# the .config(\"option\", \"value\") arguments allow us to perform refined file I/O\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "            .appName(\"app\") \\\n",
    "            .config(\"option\", \"value\") \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- open: string (nullable = true)\n",
      " |-- high: string (nullable = true)\n",
      " |-- low: string (nullable = true)\n",
      " |-- close: string (nullable = true)\n",
      " |-- volume: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      "\n",
      "+----------+-----+-----+-----+-----+--------+----+\n",
      "|      date| open| high|  low|close|  volume|Name|\n",
      "+----------+-----+-----+-----+-----+--------+----+\n",
      "|2013-02-08|15.07|15.12|14.63|14.75| 8407500| AAL|\n",
      "|2013-02-11|14.89|15.01|14.26|14.46| 8882000| AAL|\n",
      "|2013-02-12|14.45|14.51| 14.1|14.27| 8126000| AAL|\n",
      "|2013-02-13| 14.3|14.94|14.25|14.66|10259500| AAL|\n",
      "|2013-02-14|14.94|14.96|13.16|13.99|31879900| AAL|\n",
      "|2013-02-15|13.93|14.61|13.93| 14.5|15628000| AAL|\n",
      "|2013-02-19|14.33|14.56|14.08|14.26|11354400| AAL|\n",
      "|2013-02-20|14.17|14.26|13.15|13.33|14725200| AAL|\n",
      "|2013-02-21|13.62|13.95| 12.9|13.37|11922100| AAL|\n",
      "|2013-02-22|13.57| 13.6|13.21|13.57| 6071400| AAL|\n",
      "|2013-02-25| 13.6|13.76| 13.0|13.02| 7186400| AAL|\n",
      "|2013-02-26|13.14|13.42| 12.7|13.26| 9419000| AAL|\n",
      "|2013-02-27|13.28|13.62|13.18|13.41| 7390500| AAL|\n",
      "|2013-02-28|13.49|13.63|13.39|13.43| 6143600| AAL|\n",
      "|2013-03-01|13.37|13.95|13.32|13.61| 7376800| AAL|\n",
      "|2013-03-04| 13.5|14.07|13.47| 13.9| 8174800| AAL|\n",
      "|2013-03-05|14.01|14.05|13.71|14.05| 7676100| AAL|\n",
      "|2013-03-06|14.52|14.68|14.25|14.57|13243200| AAL|\n",
      "|2013-03-07| 14.7|14.93| 14.5|14.82| 9125300| AAL|\n",
      "|2013-03-08|14.99| 15.2|14.84|14.92|10593700| AAL|\n",
      "+----------+-----+-----+-----+-----+--------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stocks = spark.read.csv('file:///' + os.getcwd() + '/all_stocks_5yr.csv', header=True)\n",
    "stocks.printSchema()\n",
    "stocks.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"volume\" should be considered a numeric column; changing\n",
    "stocks = stocks.withColumn(\"volume\", stocks[\"volume\"].cast(\"int\"))\n",
    "stocks = stocks.withColumn(\"date\", stocks[\"date\"].cast(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- open: string (nullable = true)\n",
      " |-- high: string (nullable = true)\n",
      " |-- low: string (nullable = true)\n",
      " |-- close: string (nullable = true)\n",
      " |-- volume: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      "\n",
      "+----------+-----+-----+-----+-----+--------+----+\n",
      "|      date| open| high|  low|close|  volume|Name|\n",
      "+----------+-----+-----+-----+-----+--------+----+\n",
      "|2013-02-08|15.07|15.12|14.63|14.75| 8407500| AAL|\n",
      "|2013-02-11|14.89|15.01|14.26|14.46| 8882000| AAL|\n",
      "|2013-02-12|14.45|14.51| 14.1|14.27| 8126000| AAL|\n",
      "|2013-02-13| 14.3|14.94|14.25|14.66|10259500| AAL|\n",
      "|2013-02-14|14.94|14.96|13.16|13.99|31879900| AAL|\n",
      "|2013-02-15|13.93|14.61|13.93| 14.5|15628000| AAL|\n",
      "|2013-02-19|14.33|14.56|14.08|14.26|11354400| AAL|\n",
      "|2013-02-20|14.17|14.26|13.15|13.33|14725200| AAL|\n",
      "|2013-02-21|13.62|13.95| 12.9|13.37|11922100| AAL|\n",
      "|2013-02-22|13.57| 13.6|13.21|13.57| 6071400| AAL|\n",
      "|2013-02-25| 13.6|13.76| 13.0|13.02| 7186400| AAL|\n",
      "|2013-02-26|13.14|13.42| 12.7|13.26| 9419000| AAL|\n",
      "|2013-02-27|13.28|13.62|13.18|13.41| 7390500| AAL|\n",
      "|2013-02-28|13.49|13.63|13.39|13.43| 6143600| AAL|\n",
      "|2013-03-01|13.37|13.95|13.32|13.61| 7376800| AAL|\n",
      "|2013-03-04| 13.5|14.07|13.47| 13.9| 8174800| AAL|\n",
      "|2013-03-05|14.01|14.05|13.71|14.05| 7676100| AAL|\n",
      "|2013-03-06|14.52|14.68|14.25|14.57|13243200| AAL|\n",
      "|2013-03-07| 14.7|14.93| 14.5|14.82| 9125300| AAL|\n",
      "|2013-03-08|14.99| 15.2|14.84|14.92|10593700| AAL|\n",
      "+----------+-----+-----+-----+-----+--------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stocks.printSchema()\n",
    "stocks.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+\n",
      "| Name|      Date|   Volume|\n",
      "+-----+----------+---------+\n",
      "|   VZ|2014-02-24|618237630|\n",
      "|   GE|2015-11-17|431332632|\n",
      "|  BAC|2016-02-11|375088650|\n",
      "|   FB|2013-07-25|365380568|\n",
      "|  PFE|2016-04-05|284468054|\n",
      "|  MRO|2016-03-01|273996613|\n",
      "|  AMD|2017-05-02|268336455|\n",
      "| AAPL|2014-01-28|266833581|\n",
      "|  KMI|2014-11-26|251563883|\n",
      "| MSFT|2013-07-19|248354245|\n",
      "| CSCO|2013-11-14|243255407|\n",
      "|    F|2013-12-18|220362796|\n",
      "| AMAT|2015-04-27|219415189|\n",
      "|  DAL|2013-09-10|206363059|\n",
      "|  CHK|2016-03-04|188966428|\n",
      "| NFLX|2013-10-22|181099968|\n",
      "|CMCSA|2014-02-13|166551204|\n",
      "| ORCL|2013-07-12|157674694|\n",
      "|   MU|2013-10-11|153906087|\n",
      "|  FCX|2016-01-12|141597285|\n",
      "+-----+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "\n",
    "from pyspark.sql.functions import max, col\n",
    "\n",
    "# Step 1: Compute max volume per stock\n",
    "max_volume_per_stock = stocks.groupBy(\"Name\") \\\n",
    "    .agg(max(\"volume\").alias(\"max_volume\"))\n",
    "\n",
    "# Step 2: Alias both DataFrames before join\n",
    "stocks_alias = stocks.alias(\"s\")\n",
    "max_vol_alias = max_volume_per_stock.alias(\"m\")\n",
    "\n",
    "# Step 3: Join and select clearly from the aliased versions\n",
    "most_trans_per_ticker = stocks_alias \\\n",
    "    .join(\n",
    "        max_vol_alias,\n",
    "        (col(\"s.Name\") == col(\"m.Name\")) &\n",
    "        (col(\"s.volume\") == col(\"m.max_volume\")),\n",
    "        how=\"inner\"\n",
    "    ) \\\n",
    "    .select(\n",
    "        col(\"s.Name\").alias(\"Name\"),\n",
    "        col(\"s.date\").alias(\"Date\"),\n",
    "        col(\"s.volume\").alias(\"Volume\")\n",
    "    ) \\\n",
    "    .orderBy(col(\"Volume\").desc())\n",
    "\n",
    "most_trans_per_ticker.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+\n",
      "| Name|      date|   volume|\n",
      "+-----+----------+---------+\n",
      "|   VZ|2014-02-24|618237630|\n",
      "|   GE|2015-11-17|431332632|\n",
      "|  BAC|2016-02-11|375088650|\n",
      "|   FB|2013-07-25|365380568|\n",
      "|  PFE|2016-04-05|284468054|\n",
      "|  MRO|2016-03-01|273996613|\n",
      "|  AMD|2017-05-02|268336455|\n",
      "| AAPL|2014-01-28|266833581|\n",
      "|  KMI|2014-11-26|251563883|\n",
      "| MSFT|2013-07-19|248354245|\n",
      "| CSCO|2013-11-14|243255407|\n",
      "|    F|2013-12-18|220362796|\n",
      "| AMAT|2015-04-27|219415189|\n",
      "|  DAL|2013-09-10|206363059|\n",
      "|  CHK|2016-03-04|188966428|\n",
      "| NFLX|2013-10-22|181099968|\n",
      "|CMCSA|2014-02-13|166551204|\n",
      "| ORCL|2013-07-12|157674694|\n",
      "|   MU|2013-10-11|153906087|\n",
      "|  FCX|2016-01-12|141597285|\n",
      "+-----+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OPTION B - SPARKSQL\n",
    "\n",
    "stocks.createOrReplaceTempView(\"stocks\")\n",
    "query = spark.sql(\"\"\"\n",
    "    SELECT s.Name, s.date, s.volume\n",
    "    FROM stocks s\n",
    "    INNER JOIN (\n",
    "        SELECT Name, MAX(volume) AS max_volume\n",
    "        FROM stocks\n",
    "        GROUP BY Name\n",
    "    ) m\n",
    "    ON s.Name = m.Name AND s.volume = m.max_volume\n",
    "    ORDER BY s.volume DESC\n",
    "\"\"\")\n",
    "\n",
    "query.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "avg_volume_per_month = stocks \\\n",
    "    .select(\n",
    "        date_format(col(\"date\"), \"MMM yyyy\").alias(\"date\"),\n",
    "        col(\"volume\")\n",
    "    ) \\\n",
    "    .groupBy(col(\"date\")) \\\n",
    "    .agg(avg(\"volume\").alias(\"avg_volume\")) \\\n",
    "    .orderBy(col(\"date\"), ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|    date|        avg_volume|\n",
      "+--------+------------------+\n",
      "|Apr 2013| 4990292.249235766|\n",
      "|Apr 2014| 4712436.740587831|\n",
      "|Apr 2015|4049128.5425065733|\n",
      "|Apr 2016| 4403273.369344325|\n",
      "|Apr 2017|3879889.4020380294|\n",
      "|Aug 2013|3936255.4692568844|\n",
      "|Aug 2014|  3277133.94670969|\n",
      "|Aug 2015| 4910543.650503291|\n",
      "|Aug 2016|3645052.5863453816|\n",
      "|Aug 2017|3479362.4257066296|\n",
      "|Dec 2013|4092123.8206644976|\n",
      "|Dec 2014|3991512.5363263786|\n",
      "|Dec 2015| 4406736.627640037|\n",
      "|Dec 2016|4130377.3358465354|\n",
      "|Dec 2017|3919747.9897999605|\n",
      "|Feb 2013|  5261788.80732293|\n",
      "|Feb 2014| 4918514.594747739|\n",
      "|Feb 2015| 4254824.743407599|\n",
      "|Feb 2016| 5756484.877016129|\n",
      "|Feb 2017| 4255274.505789474|\n",
      "+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "avg_volume_per_month.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION B - SPARKSQL\n",
    "\n",
    "r2 = spark.sql(\"\"\"\n",
    "\n",
    "    SELECT \n",
    "        date_format(date, \"MMM yyyy\") AS month,\n",
    "        AVG(volume) AS avg_volume\n",
    "    FROM stocks\n",
    "    GROUP BY date_format(date, \"MMM yyyy\")\n",
    "    ORDER BY month ASC\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|   month|        avg_volume|\n",
      "+--------+------------------+\n",
      "|Apr 2013| 4990292.249235766|\n",
      "|Apr 2014| 4712436.740587831|\n",
      "|Apr 2015|4049128.5425065733|\n",
      "|Apr 2016| 4403273.369344325|\n",
      "|Apr 2017|3879889.4020380294|\n",
      "|Aug 2013|3936255.4692568844|\n",
      "|Aug 2014|  3277133.94670969|\n",
      "|Aug 2015| 4910543.650503291|\n",
      "|Aug 2016|3645052.5863453816|\n",
      "|Aug 2017|3479362.4257066296|\n",
      "|Dec 2013|4092123.8206644976|\n",
      "|Dec 2014|3991512.5363263786|\n",
      "|Dec 2015| 4406736.627640037|\n",
      "|Dec 2016|4130377.3358465354|\n",
      "|Dec 2017|3919747.9897999605|\n",
      "|Feb 2013|  5261788.80732293|\n",
      "|Feb 2014| 4918514.594747739|\n",
      "|Feb 2015| 4254824.743407599|\n",
      "|Feb 2016| 5756484.877016129|\n",
      "|Feb 2017| 4255274.505789474|\n",
      "+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3\n",
    "avg_volume_per_tick = stocks \\\n",
    "    .select(\n",
    "        col(\"Name\"),\n",
    "        col(\"volume\")\n",
    "    ) \\\n",
    "    .groupBy(col(\"Name\")) \\\n",
    "    .agg(avg(\"volume\").alias(\"avg_volume\")) \\\n",
    "    .orderBy(col(\"avg_volume\"), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "| Name|          avg_volume|\n",
      "+-----+--------------------+\n",
      "|  BAC| 9.363379951628277E7|\n",
      "| AAPL| 5.404789973550437E7|\n",
      "|   GE| 4.211568283240667E7|\n",
      "|    F|  3.44623748943606E7|\n",
      "|   FB| 3.435926520969023E7|\n",
      "| MSFT| 3.386946274583002E7|\n",
      "|  AMD| 3.251903779666402E7|\n",
      "|   MU| 3.024841118903892E7|\n",
      "| INTC|2.9326713900714852E7|\n",
      "| CSCO|2.8654349631453533E7|\n",
      "|  PFE|2.8218910923749007E7|\n",
      "|    T|2.5298330478951547E7|\n",
      "|  CHK|2.4957711172359016E7|\n",
      "|CMCSA|2.4329297557585385E7|\n",
      "|  FCX| 2.354921657426529E7|\n",
      "|    C| 2.068675837807784E7|\n",
      "|  WFC|1.8511480962668784E7|\n",
      "|  JPM|1.6589033246227164E7|\n",
      "|   RF|1.6398451548848292E7|\n",
      "| NFLX|1.6208007963463066E7|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_volume_per_tick.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 91:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------------------+\n",
      "| Name|      Date|            Spread|\n",
      "+-----+----------+------------------+\n",
      "| AMZN|2018-02-05|            138.26|\n",
      "| PCLN|2017-11-07|109.90000000000009|\n",
      "|  CMG|2015-11-20|              80.5|\n",
      "|  AZO|2017-12-05|59.694999999999936|\n",
      "| GOOG|2018-02-06| 58.57000000000005|\n",
      "|GOOGL|2018-02-05|             58.25|\n",
      "| REGN|2015-09-28| 56.90500000000003|\n",
      "| PRGO|2015-04-08|51.097999999999985|\n",
      "|  HUM|2015-05-29| 43.38499999999999|\n",
      "| ULTA|2015-08-24|             43.22|\n",
      "|  MCK|2015-08-24|           42.1799|\n",
      "|  HCA|2015-08-24|             42.06|\n",
      "| BIIB|2014-03-21|41.920000000000016|\n",
      "| ALGN|2017-12-04|             35.25|\n",
      "|  BLK|2018-02-05| 34.52999999999997|\n",
      "|  ADS|2016-01-28| 33.56999999999999|\n",
      "|  MTD|2018-02-05|           33.2595|\n",
      "|   BA|2018-02-05|32.610000000000014|\n",
      "|  AGN|2015-10-21|           32.4999|\n",
      "|  TDG|2017-01-20|             32.25|\n",
      "+-----+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "\n",
    "# Step 0: Create a new DataFrame with the spread column\n",
    "stocks_with_spread = stocks.withColumn(\"spread\", col(\"high\") - col(\"low\"))\n",
    "\n",
    "# Step 1: Compute max spread per stock\n",
    "max_spread_per_stock = stocks_with_spread.groupBy(\"Name\") \\\n",
    "    .agg(max(\"spread\").alias(\"max_spread\"))\n",
    "\n",
    "# Step 2: Alias both DataFrames before join\n",
    "stocks_alias = stocks_with_spread.alias(\"s\")\n",
    "max_spread_alias = max_spread_per_stock.alias(\"m\")\n",
    "\n",
    "# Step 3: Join and select desired columns\n",
    "max_spread_dates = stocks_alias \\\n",
    "    .join(\n",
    "        max_spread_alias,\n",
    "        (col(\"s.Name\") == col(\"m.Name\")) &\n",
    "        (col(\"s.spread\") == col(\"m.max_spread\")),\n",
    "        how=\"inner\"\n",
    "    ) \\\n",
    "    .select(\n",
    "        col(\"s.Name\").alias(\"Name\"),\n",
    "        col(\"s.date\").alias(\"Date\"),\n",
    "        col(\"s.spread\").alias(\"Spread\")\n",
    "    ) \\\n",
    "    .orderBy(col(\"Spread\").desc())\n",
    "\n",
    "max_spread_dates.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "| Name|   avg_stock_price|\n",
      "+-----+------------------+\n",
      "| PCLN|1346.7126984126985|\n",
      "|  AZO| 768.8588492063492|\n",
      "|GOOGL| 763.2142063492068|\n",
      "| GOOG| 743.4851190476194|\n",
      "| AMZN| 699.5231349206346|\n",
      "|  CMG|428.56464285714287|\n",
      "| REGN|394.49996031746036|\n",
      "|  MTD| 375.5649206349207|\n",
      "|  BLK|350.08837301587295|\n",
      "| EQIX|343.77674603174603|\n",
      "| BIIB| 280.1989682539682|\n",
      "|  SHW| 277.9422222222223|\n",
      "| ORLY|269.24904761904753|\n",
      "|  TDG|251.80250000000007|\n",
      "|  AGN|241.69857142857143|\n",
      "|  AYI|241.64035714285708|\n",
      "|  PSA|238.75015873015872|\n",
      "|  LMT|237.99261904761906|\n",
      "| CHTR|229.49678571428566|\n",
      "| ULTA|224.08111111111108|\n",
      "+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Question 5\n",
    "avg_volume_per_tick = stocks \\\n",
    "    .select(\n",
    "        col(\"Name\"),\n",
    "        col(\"close\")\n",
    "    ) \\\n",
    "    .filter(date_format(col(\"date\"), \"yyyy\") == 2016) \\\n",
    "    .groupBy(col(\"Name\")) \\\n",
    "    .agg(avg(\"close\").alias(\"avg_stock_price\")) \\\n",
    "    .orderBy(col(\"avg_stock_price\"), ascending=False) \n",
    "\n",
    "avg_volume_per_tick.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|Name|\n",
      "+----+\n",
      "|ALXN|\n",
      "| GIS|\n",
      "|   K|\n",
      "| LEN|\n",
      "|SPGI|\n",
      "| AIV|\n",
      "| AVY|\n",
      "|BF.B|\n",
      "| MMM|\n",
      "| PKI|\n",
      "| PPG|\n",
      "|  RF|\n",
      "| AXP|\n",
      "|  CI|\n",
      "| IRM|\n",
      "| WEC|\n",
      "|INFO|\n",
      "| PFG|\n",
      "|  PM|\n",
      "| SNA|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 6\n",
    "\n",
    "all_tickers = stocks \\\n",
    "    .select(col(\"Name\")) \\\n",
    "    .distinct() \n",
    "\n",
    "all_tickers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
